{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`tfds.core.add_checksums_dir` is deprecated. Refactor dataset in self-contained folders (`my_dataset/` folder containing my_dataset.py, my_dataset_test.py, dummy_data/, checksums.tsv). The checksum file will be automatically detected. More info at: https://www.tensorflow.org/datasets/add_dataset\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "path = os.path.realpath(os.path.join(os.getcwd(),'../'))\n",
    "sys.path.insert(0, path)\n",
    "import astro_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\cmd\\1.0.0...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23b3d3c02d13461cbdfe9132a6481676"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "003f2f7b93194d0cba22fd877f885177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eecd1bb298494d9e803736c816c128f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21786d499c554733ad7c0af8c82c7d22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2e6c7bbfe104b6897cad85a4b80cc24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train examples...: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b0733aa990a44e59f347a43f41e3034"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "KeyError: Failed to encode example:\n{'image': array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'label': array([0.1462 , 0.6242 , 2.87986, 0.57995, 0.91447, 0.69786])}\n'label'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:379\u001B[0m, in \u001B[0;36mSplitBuilder._build_from_generator\u001B[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001B[0m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m   example \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_features\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:235\u001B[0m, in \u001B[0;36mFeaturesDict.encode_example\u001B[1;34m(self, example_dict)\u001B[0m\n\u001B[0;32m    234\u001B[0m example \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 235\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, (feature, example_value) \u001B[38;5;129;01min\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mzip_dict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feature_dict,\n\u001B[0;32m    236\u001B[0m                                                   example_dict):\n\u001B[0;32m    237\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:107\u001B[0m, in \u001B[0;36mzip_dict\u001B[1;34m(*dicts)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mchain(\u001B[38;5;241m*\u001B[39mdicts)):  \u001B[38;5;66;03m# set merge all keys\u001B[39;00m\n\u001B[0;32m    106\u001B[0m   \u001B[38;5;66;03m# Will raise KeyError if the dict don't have the same keys\u001B[39;00m\n\u001B[1;32m--> 107\u001B[0m   \u001B[38;5;28;01myield\u001B[39;00m key, \u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdicts\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:107\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mchain(\u001B[38;5;241m*\u001B[39mdicts)):  \u001B[38;5;66;03m# set merge all keys\u001B[39;00m\n\u001B[0;32m    106\u001B[0m   \u001B[38;5;66;03m# Will raise KeyError if the dict don't have the same keys\u001B[39;00m\n\u001B[1;32m--> 107\u001B[0m   \u001B[38;5;28;01myield\u001B[39;00m key, \u001B[38;5;28mtuple\u001B[39m(\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m dicts)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#ds, info = tfds.load(name='cmd', split='train', with_info=True, as_supervised=True, simulation='SIMBA',sim_set='LH',field='MTOT')\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m ds, info \u001B[38;5;241m=\u001B[39m \u001B[43mtfds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcmd\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_supervised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuilder_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msimulation\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSIMBA\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msim_set\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCV\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfield\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMtot\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:327\u001B[0m, in \u001B[0;36mload\u001B[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m    326\u001B[0m   download_and_prepare_kwargs \u001B[38;5;241m=\u001B[39m download_and_prepare_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m--> 327\u001B[0m   dbuilder\u001B[38;5;241m.\u001B[39mdownload_and_prepare(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdownload_and_prepare_kwargs)\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m as_dataset_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    330\u001B[0m   as_dataset_kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:481\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[1;34m(self, download_dir, download_config, file_format)\u001B[0m\n\u001B[0;32m    479\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mread_from_directory(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_dir)\n\u001B[0;32m    480\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 481\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    486\u001B[0m   \u001B[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001B[39;00m\n\u001B[0;32m    487\u001B[0m   \u001B[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001B[39;00m\n\u001B[0;32m    488\u001B[0m   \u001B[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001B[39;00m\n\u001B[0;32m    489\u001B[0m   \u001B[38;5;66;03m# when reading from package data.\u001B[39;00m\n\u001B[0;32m    490\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdownload_size \u001B[38;5;241m=\u001B[39m dl_manager\u001B[38;5;241m.\u001B[39mdownloaded_size\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1218\u001B[0m, in \u001B[0;36mGeneratorBasedBuilder._download_and_prepare\u001B[1;34m(self, dl_manager, download_config)\u001B[0m\n\u001B[0;32m   1207\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m split_name, generator \u001B[38;5;129;01min\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mtqdm(\n\u001B[0;32m   1208\u001B[0m       split_generators\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[0;32m   1209\u001B[0m       desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating splits...\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1210\u001B[0m       unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m splits\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1211\u001B[0m       leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1212\u001B[0m   ):\n\u001B[0;32m   1213\u001B[0m     filename_template \u001B[38;5;241m=\u001B[39m naming\u001B[38;5;241m.\u001B[39mShardedFileTemplate(\n\u001B[0;32m   1214\u001B[0m         split\u001B[38;5;241m=\u001B[39msplit_name,\n\u001B[0;32m   1215\u001B[0m         dataset_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m   1216\u001B[0m         data_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_path,\n\u001B[0;32m   1217\u001B[0m         filetype_suffix\u001B[38;5;241m=\u001B[39mpath_suffix)\n\u001B[1;32m-> 1218\u001B[0m     future \u001B[38;5;241m=\u001B[39m \u001B[43msplit_builder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit_split_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1219\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msplit_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename_template\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename_template\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_shuffling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdisable_shuffling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1224\u001B[0m     split_info_futures\u001B[38;5;241m.\u001B[39mappend(future)\n\u001B[0;32m   1226\u001B[0m \u001B[38;5;66;03m# Process the result of the beam pipeline.\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:310\u001B[0m, in \u001B[0;36mSplitBuilder.submit_split_generation\u001B[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Depending on the type of generator, we use the corresponding\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# `_build_from_xyz` method.\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(generator, collections\u001B[38;5;241m.\u001B[39mabc\u001B[38;5;241m.\u001B[39mIterable):\n\u001B[1;32m--> 310\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_from_generator(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbuild_kwargs)\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Otherwise, beam required\u001B[39;00m\n\u001B[0;32m    312\u001B[0m   unknown_generator_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    313\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInvalid split generator value for split `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msplit_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    314\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected generator or apache_beam object. Got: \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    315\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(generator)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:381\u001B[0m, in \u001B[0;36mSplitBuilder._build_from_generator\u001B[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001B[0m\n\u001B[0;32m    379\u001B[0m     example \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_features\u001B[38;5;241m.\u001B[39mencode_example(example)\n\u001B[0;32m    380\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m--> 381\u001B[0m     \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mFailed to encode example:\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mexample\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    382\u001B[0m   writer\u001B[38;5;241m.\u001B[39mwrite(key, example)\n\u001B[0;32m    383\u001B[0m shard_lengths, total_size \u001B[38;5;241m=\u001B[39m writer\u001B[38;5;241m.\u001B[39mfinalize()\n",
      "File \u001B[1;32mE:\\Loz\\University\\Year 4\\SUMMER PROJECT\\astro_datasets\\venv\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:381\u001B[0m, in \u001B[0;36mreraise\u001B[1;34m(e, prefix, suffix)\u001B[0m\n\u001B[0;32m    379\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    380\u001B[0m     exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 381\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m exception \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# Otherwise, modify the exception in-place\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(e\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: KeyError: Failed to encode example:\n{'image': array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'label': array([0.1462 , 0.6242 , 2.87986, 0.57995, 0.91447, 0.69786])}\n'label'"
     ]
    }
   ],
   "source": [
    "#ds, info = tfds.load(name='cmd', split='train', with_info=True, as_supervised=True, simulation='SIMBA',sim_set='LH',field='MTOT')\n",
    "ds, info = tfds.load(name='cmd', split='train', with_info=True, as_supervised=True, builder_kwargs={'simulation': 'SIMBA', 'sim_set': 'CV', 'field': 'Mtot'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}